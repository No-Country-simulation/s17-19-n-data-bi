import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd

# Cargar los datasets
productos = pd.read_parquet('/workspaces/s17-19-n-data-bi/data/Productos.parquet')
sucursales = pd.read_parquet('/workspaces/s17-19-n-data-bi/data/Sucursales.parquet')
data = pd.read_parquet('/workspaces/s17-19-n-data-bi/data/Data.parquet')

# Crear una tabla con todas las combinaciones de sucursales y productos
stock_inicial = pd.merge(sucursales[['id_sucursal']], productos[['skuagr_2']], how='cross')
stock_inicial['stock_inicial'] = 100  # Asignar 100 unidades como stock inicial

# Calcular el stock restante después de las transacciones
transacciones_agrupadas = data.groupby(['id_sucursal', 'skuagr_2']).agg({'cantidad_dispensada': 'sum'}).reset_index()
stock_actualizado = pd.merge(stock_inicial, transacciones_agrupadas, on=['id_sucursal', 'skuagr_2'], how='left')
stock_actualizado['cantidad_dispensada'] = stock_actualizado['cantidad_dispensada'].fillna(0)
stock_actualizado['stock_disponible'] = stock_actualizado['stock_inicial'] - stock_actualizado['cantidad_dispensada']

# Definir X y y
stock_actualizado['hay_stock'] = stock_actualizado['stock_disponible'] > 0
stock_actualizado['hay_stock'] = stock_actualizado['hay_stock'].astype(int)
X = stock_actualizado.drop(['stock_inicial', 'cantidad_dispensada', 'stock_disponible', 'hay_stock'], axis=1)
y = stock_actualizado['hay_stock']

# Aplicar One-Hot Encoding a las variables categóricas si es necesario
X = pd.get_dummies(X, drop_first=True)

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Escalar los datos
scaler = StandardScaler()
X_train_np = scaler.fit_transform(X_train)
X_test_np = scaler.transform(X_test)

# Convertir a tensores de PyTorch
X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)
X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)

# Definir el modelo en PyTorch
class StockModel(nn.Module):
    def __init__(self):
        super(StockModel, self).__init__()
        self.fc1 = nn.Linear(X_train_tensor.shape[1], 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
    
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.sigmoid(self.fc3(x))
        return x

model = StockModel()

# Definir el optimizador y la función de pérdida
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Entrenar el modelo
for epoch in range(10):
    model.train()
    optimizer.zero_grad()
    outputs = model(X_train_tensor)
    loss = criterion(outputs, y_train_tensor)
    loss.backward()
    optimizer.step()
    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')

# Guardar el modelo solo los pesos del modelo
torch.save(model.state_dict(), '/workspaces/s17-19-n-data-bi/models/stock_verification_model.pth')
